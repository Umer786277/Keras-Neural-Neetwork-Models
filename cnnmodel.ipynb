{"cells":[{"cell_type":"code","source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dropout, Dense, Flatten\n","from keras.optimizers import SGD\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.utils import np_utils as u\n","from keras.datasets import cifar10\n","from tensorflow.keras.optimizers import Adam"],"metadata":{"id":"IdpkmvOpLTy9","executionInfo":{"status":"ok","timestamp":1669405565635,"user_tz":480,"elapsed":412,"user":{"displayName":"Umar Farooq BSIT-M1","userId":"03227558247907321380"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#How to Develop a CNN From Scratch for CIFAR-10 Photo Classification\n","\n","\n","#Lets start by loading the Cifar10 data\n","\n","(X, y), (X_test, y_test) = cifar10.load_data()\n","\n","#Keep in mind the images are in RGB\n","#So we can normalise the data by diving by 255\n","#The data is in integers therefore we need to convert them to float first\n","X, X_test = X.astype('float32')/255.0, X_test.astype('float32')/255.0\n","\n","#Then we convert the y values into one-hot vectors\n","#The cifar10 has only 10 classes, thats is why we specify a one-hot\n","#vector of width/class 10\n","y, y_test = u.to_categorical(y, 10), u.to_categorical(y_test, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"klluc1RNLW4o","executionInfo":{"status":"ok","timestamp":1669404558794,"user_tz":480,"elapsed":5210,"user":{"displayName":"Umar Farooq BSIT-M1","userId":"03227558247907321380"}},"outputId":"5923036c-9732-4b01-e450-3139000eeb78"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 2s 0us/step\n"]}]},{"cell_type":"code","source":["\n","#Now we can go ahead and create our Convolution model\n","model = Sequential()\n","#We want to output 32 features maps. The kernel size is going to be\n","#3x3 and we specify our input shape to be 32x32 with 3 channels\n","#Padding=same means we want the same dimensional output as input\n","#activation specifies the activation function\n","model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same',\n","                 activation='relu'))\n","#20% of the nodes are set to 0\n","model.add(Dropout(0.2))\n","#now we add another convolution layer, again with a 3x3 kernel\n","#This time our padding=valid this means that the output dimension can\n","#take any form\n","model.add(Conv2D(32, (3, 3), activation='relu', padding='valid'))\n","#maxpool with a kernet of 2x2\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","#In a convolution NN, we neet to flatten our data before we can\n","#input it into the ouput/dense layer\n","model.add(Flatten())\n","#Dense layer with 512 hidden units\n","model.add(Dense(512, activation='relu'))\n","#this time we set 30% of the nodes to 0 to minimize overfitting\n","model.add(Dropout(0.3))\n","#Finally the output dense layer with 10 hidden units corresponding to\n","#our 10 classe\n","model.add(Dense(10, activation='softmax'))"],"metadata":{"id":"hdr9nvEXRyGP","executionInfo":{"status":"ok","timestamp":1669404769388,"user_tz":480,"elapsed":366,"user":{"displayName":"Umar Farooq BSIT-M1","userId":"03227558247907321380"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mmABD12kR1YS","executionInfo":{"status":"ok","timestamp":1669405024987,"user_tz":480,"elapsed":409,"user":{"displayName":"Umar Farooq BSIT-M1","userId":"03227558247907321380"}},"outputId":"74d8826c-9e43-4500-b302-ae2d0753318e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_2 (Conv2D)           (None, 32, 32, 32)        896       \n","                                                                 \n"," dropout (Dropout)           (None, 32, 32, 32)        0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 30, 30, 32)        9248      \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_1 (Flatten)         (None, 7200)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 512)               3686912   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 3,702,186\n","Trainable params: 3,702,186\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["The Dropout Layer\n","Another typical characteristic of CNNs is a Dropout layer. The Dropout layer is a mask that nullifies the contribution of some neurons towards the next layer and leaves unmodified all others.**bold text**"],"metadata":{"id":"oKVwmYEhTLAP"}},{"cell_type":"code","source":["#Few simple configurations\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=SGD(momentum=0.5, decay=0.0004), metrics=['accuracy'])"],"metadata":{"id":"qlvXRe0dUdpd","executionInfo":{"status":"ok","timestamp":1669405647252,"user_tz":480,"elapsed":418,"user":{"displayName":"Umar Farooq BSIT-M1","userId":"03227558247907321380"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#Run the algorithm!\n","model.fit(X, y, validation_data=(X_test, y_test), epochs=25,\n","          batch_size=512)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z1VOq8XRVLdE","executionInfo":{"status":"ok","timestamp":1669405859484,"user_tz":480,"elapsed":79818,"user":{"displayName":"Umar Farooq BSIT-M1","userId":"03227558247907321380"}},"outputId":"4848a8d5-dcfc-48d2-82f8-0d555204ed3a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","98/98 [==============================] - 11s 34ms/step - loss: 2.1625 - accuracy: 0.2060 - val_loss: 2.0200 - val_accuracy: 0.2981\n","Epoch 2/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.9529 - accuracy: 0.3032 - val_loss: 1.9120 - val_accuracy: 0.3299\n","Epoch 3/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.8618 - accuracy: 0.3408 - val_loss: 1.8201 - val_accuracy: 0.3674\n","Epoch 4/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.7990 - accuracy: 0.3650 - val_loss: 1.7587 - val_accuracy: 0.3906\n","Epoch 5/25\n","98/98 [==============================] - 3s 30ms/step - loss: 1.7457 - accuracy: 0.3846 - val_loss: 1.7174 - val_accuracy: 0.4062\n","Epoch 6/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.7004 - accuracy: 0.4023 - val_loss: 1.6739 - val_accuracy: 0.4174\n","Epoch 7/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.6624 - accuracy: 0.4144 - val_loss: 1.6249 - val_accuracy: 0.4329\n","Epoch 8/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.6295 - accuracy: 0.4255 - val_loss: 1.5949 - val_accuracy: 0.4369\n","Epoch 9/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.6047 - accuracy: 0.4343 - val_loss: 1.5784 - val_accuracy: 0.4460\n","Epoch 10/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.5790 - accuracy: 0.4463 - val_loss: 1.5613 - val_accuracy: 0.4491\n","Epoch 11/25\n","98/98 [==============================] - 3s 29ms/step - loss: 1.5588 - accuracy: 0.4499 - val_loss: 1.5292 - val_accuracy: 0.4637\n","Epoch 12/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.5369 - accuracy: 0.4593 - val_loss: 1.5006 - val_accuracy: 0.4739\n","Epoch 13/25\n","98/98 [==============================] - 3s 29ms/step - loss: 1.5259 - accuracy: 0.4627 - val_loss: 1.4864 - val_accuracy: 0.4819\n","Epoch 14/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.5068 - accuracy: 0.4698 - val_loss: 1.4907 - val_accuracy: 0.4725\n","Epoch 15/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.4911 - accuracy: 0.4760 - val_loss: 1.4634 - val_accuracy: 0.4903\n","Epoch 16/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.4807 - accuracy: 0.4805 - val_loss: 1.4683 - val_accuracy: 0.4838\n","Epoch 17/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.4656 - accuracy: 0.4840 - val_loss: 1.4616 - val_accuracy: 0.4837\n","Epoch 18/25\n","98/98 [==============================] - 3s 30ms/step - loss: 1.4565 - accuracy: 0.4883 - val_loss: 1.4333 - val_accuracy: 0.5044\n","Epoch 19/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.4420 - accuracy: 0.4934 - val_loss: 1.4193 - val_accuracy: 0.4994\n","Epoch 20/25\n","98/98 [==============================] - 3s 29ms/step - loss: 1.4297 - accuracy: 0.4990 - val_loss: 1.4138 - val_accuracy: 0.5038\n","Epoch 21/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.4177 - accuracy: 0.5021 - val_loss: 1.3993 - val_accuracy: 0.5108\n","Epoch 22/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.4067 - accuracy: 0.5038 - val_loss: 1.3856 - val_accuracy: 0.5166\n","Epoch 23/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.3989 - accuracy: 0.5059 - val_loss: 1.3692 - val_accuracy: 0.5203\n","Epoch 24/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.3874 - accuracy: 0.5118 - val_loss: 1.3614 - val_accuracy: 0.5263\n","Epoch 25/25\n","98/98 [==============================] - 3s 28ms/step - loss: 1.3768 - accuracy: 0.5176 - val_loss: 1.3629 - val_accuracy: 0.5250\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fd624d9a990>"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":[],"metadata":{"id":"AmUtgdoKX4Eb"}}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyOV0WZt8ViWt/HBtwO/XIyI"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}